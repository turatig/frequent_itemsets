{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "frequent_itemsets.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J00vwdMle-Nx"
      },
      "source": [
        "**MARKET BASKET ANALYSIS NOTEBOOK**"
      ],
      "id": "J00vwdMle-Nx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOVdeW-efZ3z"
      },
      "source": [
        "Dowload and preprocess dataset"
      ],
      "id": "LOVdeW-efZ3z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ba4125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c209e1-c273-4a74-f64e-e6857066d89a"
      },
      "source": [
        "!pip install kaggle\n",
        "!pip install pandas\n",
        "\n",
        "import os,zipfile,json,re\n",
        "import functools as ft\n",
        "\n",
        "os.environ['KAGGLE_USERNAME']='giacomoturati1'\n",
        "os.environ['KAGGLE_KEY']='7d34a1aefc3558065164b70c24ce27ed'\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "def get_dataset():\n",
        "\n",
        "  #execute only if the dataset was not already downloaded\n",
        "  if 'old-newspaper.tsv' not in os.listdir():\n",
        "    api=KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    api.dataset_download_file('alvations/old-newspapers','old-newspaper.tsv')\n",
        "\n",
        "    with zipfile.ZipFile('old-newspaper.tsv.zip','r') as _zip:\n",
        "      _zip.extractall()\n",
        "\n",
        "#languages: subset of languages to be considered during the market-basket analysis\n",
        "def read_dataset_from_disk(languages=None):\n",
        "  with open('old-newspaper.tsv','r') as f:\n",
        "    #skip header line\n",
        "    next(f)\n",
        "    for line in f:\n",
        "      l=line.split('\\t')\n",
        "      if languages is not None and l[0] not in languages: continue\n",
        "\n",
        "      #get a list of words as basket skipping any sequence of non-alphabetical characters\n",
        "      basket=re.split(r'[^a-zA-Z]+',l[3])\n",
        "      #remove any empty string\n",
        "      basket=[word.lower() for word in basket if word!='']\n",
        "      yield basket\n",
        "\n",
        "#create json wich contains an array of baskets (lists of words)\n",
        "def create_test_json_dataset(languages=None):\n",
        "  baskets=[]\n",
        "\n",
        "  filename=ft.reduce(lambda i,j:i+'_'+j,languages) if languages is not None else \"all_languages\"\n",
        "  filename+='.json'\n",
        "\n",
        "  #execute only if the dataset was not already created\n",
        "  if filename not in os.listdir():\n",
        "    for line in read_dataset_from_disk(languages):\n",
        "      baskets.append(line)\n",
        "\n",
        "    f=open(filename,'w')\n",
        "    f.write(json.dumps(baskets,indent=\"\\t\"))\n",
        "    f.close()\n",
        "\n",
        "#yield lists of words (baskets) from json file created with  \n",
        "def iter_baskets_from_json(filename):\n",
        "  theres_next=True\n",
        "  basket=[]\n",
        "\n",
        "  with open(filename,'r') as f:\n",
        "    #skip first square braket\n",
        "    next(f)\n",
        "    for line in f:\n",
        "\n",
        "      m=re.search(r'[a-zA-Z]+|\\[|\\]',line)\n",
        "      line=line[m.start():m.end()]\n",
        "\n",
        "      if line==\"[\": \n",
        "        basket=[]\n",
        "        theres_next=True\n",
        "\n",
        "      elif line==\"]\":\n",
        "        if theres_next:\n",
        "          theres_next=False\n",
        "          yield basket\n",
        "\n",
        "      else: basket.append(line)\n",
        "    \n",
        "\n",
        "\n",
        "get_dataset()\n",
        "create_test_json_dataset(['Italian'])\n",
        "\n",
        "\n"
      ],
      "id": "22ba4125",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-0BQUe4z29F",
        "outputId": "5f36ad71-376b-4303-a4fb-1117ae1a974d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "baskets=iter_baskets_from_json('Italian.json')\n",
        "\n",
        "print(next(baskets))"
      ],
      "id": "P-0BQUe4z29F",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['con', 'l', 'editore', 'crocetti', 'il', 'poeta', 'e', 'drammaturgo', 'wole', 'soyinka', 'premio', 'nobel', 'per', 'la', 'letteratura', 'aprir', 'la', 'milanesiana', 'domenica', 'prossima', 'alle', 'presso', 'la', 'sala', 'buzzati', 'di', 'via', 'balzan', 'milano', 'con', 'lui', 'nacer', 'khemir', 'tahar', 'ben', 'jelloun', 'biyi', 'bandele', 'jean', 'hatzfeld', 'ben', 'okri', 'leggeranno', 'testi', 'sul', 'tema', 'bugie', 'e', 'verit', 'dello', 'stesso', 'argomento', 'parler', 'guido', 'barbujani', 'il', 'giugno', 'alle', 'con', 'un', 'intervento', 'che', 'pubblichiamo', 'a', 'pagina']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtL-veBk1moc",
        "outputId": "0987f61b-8911-4d96-eec7-b73ac20c5300",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(next(baskets))"
      ],
      "id": "mtL-veBk1moc",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['non', 'solo', 'con', 'la', 'nuova', 'pillola', 'si', 'semplifica', 'di', 'molto', 'la', 'cura', 'basta', 'prenderne', 'una', 'al', 'mattino', 'e', 'si', 'facilita', 'l', 'aderenza', 'stessa', 'alle', 'cure', 'non', 'alta', 'con', 'le', 'terapie', 'oggi', 'in', 'uso', 'che', 'richiedono', 'tutte', 'una', 'o', 'pi', 'iniezioni', 'al', 'd']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}